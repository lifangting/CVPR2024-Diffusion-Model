# CVPR2024-Diffusion-Model
1	LaRE^2: Latent Reconstruction Error Based Method for Diffusion-Generated Image Detection  https://arxiv.org/abs/2403.17465

2	CrowdDiff: Multi-hypothesis Crowd Density Estimation using Diffusion Models   https://arxiv.org/abs/2303.12790

3	MonoDiff: Monocular 3D Object Detection and Pose Estimation with Diffusion Models

4	360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model  https://arxiv.org/abs/2401.06578

5	3DiffTection: 3D Object Detection with Geometry-aware Diffusion Features  https://arxiv.org/abs/2311.04391

6	6D-Diff: A Keypoint Diffusion Framework for 6D Object Pose Estimation  https://arxiv.org/abs/2401.00029

7	A Conditional Denoising Diffusion Probabilistic Model for Point Cloud Upsampling  https://arxiv.org/abs/2312.02719

8	A Unified Diffusion Framework for Scene-aware Human Motion Estimation from Sparse Signals  https://arxiv.org/abs/2404.04890

9	AAMDM: Accelerated Auto-regressive Motion Diffusion Model  https://arxiv.org/abs/2401.06146

10	Accelerating Diffusion Sampling with Optimized Time Steps  https://arxiv.org/abs/2402.17376

11	ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models  https://arxiv.org/abs/2311.14097

12	Action Detection via an Image Diffusion Process  https://arxiv.org/abs/2404.01051

13	AEROBLADE: Training-Free Detection of Latent Diffusion Images Using Autoencoder Reconstruction Error

14	Alchemist: Parametric Control of Material Properties with Diffusion Models

15	Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models

16	Amodal Completion via Progressive Mixed Context Diffusion

17	Analyzing and Improving the Training Dynamics of Diffusion Models

18	Arbitrary Motion Style Transfer with Multi-condition Motion Latent Diffusion Model

19	Arbitrary-Scale Image Generation and Upsampling using Latent Diffusion Model and Implicit Neural Decoder

20	As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D Diffusion Priors

21	Atlantis: Enabling Underwater Depth Estimation with Stable Diffusion

22	Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models

23	AVID: Any-Length Video Inpainting with Diffusion Model

24	Balancing Act: Distribution-Guided Debiasing in Diffusion Models

25	Bayesian Diffusion Models for 3D Shape Reconstruction

26	Beyond First-Order Tweedie: Solving Inverse Problems using Latent Diffusion

27	Beyond Textual Constraints: Learning Novel Diffusion Conditions with Fewer Examples

28	Bidirectional Autoregessive Diffusion Model for Dance Generation

29	BIVDiff: A Training-free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models

30	Boosting Diffusion Models with Moving Average Sampling in Frequency Domain

31	Building Bridges across Spatial and Temporal Resolutions: Reference-Based Super-Resolution via Change Priors and Conditional Diffusion Model

32	Cache Me if You Can: Accelerating Diffusion Models through Block Caching

33	Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion?

34	Carve3D: Improving Multiview Reconstruction Consistency for Diffusion Models with RL Finetuning

35	CAT-DM: Controllable Accelerated Virtual Try-on with Diffusion Model

36	CCEdit: Creative and Controllable Video Editing via Diffusion Models

37	CDFormer: When Degradation Prediction Embraces Diffusion Model for Blind Image Super-Resolution

38	CGI-DM: Digital Copyright Authentication for Diffusion Models via Contrasting Gradient Inversion

39	Clockwork Diffusion: Efficient Generation With Model-Step Distillation

40	Co-Speech Gesture Video Generation via Motion-Decoupled Diffusion Model

41	Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis

42	CoDi: Conditional Diffusion Distillation for Higher-Fidelity and Faster Image Generation

43	CommonCanvas: Open Diffusion Models Trained on Creative-Commons Images

44	CONFORM: Contrast is All You Need for High-Fidelity Text-to-Image Diffusion Models

45	Confronting Ambiguity in 6D Object Pose Estimation via Score-Based Diffusion on SE(3)

46	ConsistDreamer: 3D-Consistent 2D Diffusion for High-Fidelity Scene Editing

47	ConsistNet: Enforcing 3D Consistency for Multi-view Images Diffusion

48	Contrastive Denoising Score for Text-guided Latent Diffusion Image Editing

49	ConvoFusion: Multi-Modal Conversational Diffusion for Co-Speech Gesture Synthesis

50	Correcting Diffusion Generation through Resampling

51	D^4M: Dataset Distillation via Disentangled Diffusion Model

52	De-Diffusion Makes Text a Strong Cross-Modal Interface

53	DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations

54	Deep Equilibrium Diffusion Restoration with Parallel Sampling

55	DeepCache: Accelerating Diffusion Models for Free

56	DetDiffusion: Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception

57	Diff-BGM: A Diffusion Model for Video Background Music Generation

58	Diff-Plugin: Revitalizing Details for Diffusion-based Low-level Tasks

59	DiffAM: Diffusion-based Adversarial Makeup Transfer for Facial Privacy Protection

60	DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly

61	DiffCast: A Unified Framework via Residual Diffusion for Precipitation Nowcasting

62	DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image Editing

63	DiffForensics: Leveraging Diffusion Prior to Image Forgery Detection and Localization

64	DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation

65	DiffLoc: Diffusion Model for Outdoor LiDAR Localization

66	DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with Iterative Diffusion-Based Refinement

67	DiffMorpher: Unleashing the Capability of Diffusion Models for Image Morphing

68	DiffMOT: A Real-time Diffusion-based Multiple Object Tracker with Non-linear Prediction

69	DiffPerformer: Iterative Learning of Consistent Latent Guidance for Diffusion-based Human Video Generation

70	DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View Synthesis

71	DiffSal: Joint Audio and Video Learning for Diffusion Saliency Prediction

72	DiffSCI: Zero-Shot Snapshot Compressive Imaging via Iterative Spectral Diffusion Model

73	DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation

74	DiffuScene: Denoising Diffusion Models for Generative Indoor Scene Synthesis

75	Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion

76	DiffuseMix: Label-Preserving Data Augmentation with Diffusion Models

77	Diffusion 3D Features (Diff3F): Decorating Untextured Shapes with Distilled Semantic Features

78	Diffusion Handles: Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D

79	Diffusion Model Alignment Using Direct Preference Optimization

80	Diffusion Models Without Attention

81	Diffusion Reflectance Map: Single-Image Stochastic Inverse Rendering of Illumination and Reflectance

82	Diffusion Time-step Curriculum for One Image to 3D Generation

83	Diffusion-based Blind Text Image Super-Resolution

84	Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation

85	Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation

86	Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous and Instruction-guided Driving

87	Diffusion-FOF: Single-view Clothed Human Reconstruction via Diffusion-based Fourier Occupancy Field

88	DiffusionAvatars: Deferred Diffusion for High-fidelity 3D Head Avatars

89	DiffusionGAN3D: Boosting Text-guided 3D Generation and Domain Adaptation by Combining 3D GANs and Diffusion Priors

90	DiffusionLight: Light Probes for Free by Painting a Chrome Ball

91	DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data

92	DiffusionPoser: Real-time Human Motion Reconstruction From Arbitrary Sparse Sensors Using Autoregressive Diffusion

93	DiffusionRegPose: Enhancing Multi-Person Pose Estimation using a Diffusion-Based End-to-End Regression Approach

94	DiG-IN: Diffusion Guidance for Investigating Networks - Uncovering Classifier Differences, Neuron Visualisations, and Visual Counterfactual Explanations

95	Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion

96	DiSR-NeRF: Diffusion-Guided View-Consistent Super-Resolution NeRF

97	Distilling ODE Solvers of Diffusion Models into Smaller Steps

98	Distraction is All You Need: Memory-Efficient Image Immunization against Diffusion-Based Image Editing

99	DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models

100	Don’t drop your samples! Coherence-aware training benefits Conditional diffusion

101	DPHMs: Diffusion Parametric Head Models for Depth-based Tracking

102	DPMesh: Exploiting Diffusion Prior for Occluded Human Mesh Recovery

103	Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic Propagation

104	DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing

105	Draw Step by Step Like Human: Reconstructing CAD Construction Sequences from Point Clouds via Multimodal Diffusion.

106	DREAM: Diffusion Rectification and Estimation-Adaptive Models

107	DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models

108	DreamSalon: A Staged Diffusion Framework for Preserving Identity-Context in Editable Face Generation

109	Dysen-VDM: Empowering Dynamics-aware Text-to-Video Diffusion with LLMs

110	EasyDrag: Efficient Point-based Manipulation on Diffusion Models

111	ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation

112	Efficient Dataset Distillation via Minimax Diffusion

113	EfficientDreamer: High-Fidelity and Robust 3D Creation via Orthogonal-view Diffusion Priors

114	Egocentric Full Body Motion Capture with FisheyeViT and Diffusion-Based Motion Refinement

115	ElasticDiffusion: Training-free Arbitrary Size Image Generation

116	EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion Models

117	Emotional Speech-Driven 3D Body Animation via Disentangled Latent Diffusion

118	Enhance Image Classification Via Inter-Class Image Mixup With Diffusion Model

119	EpiDiff: Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion

120	Exploiting Diffusion Prior for Generalizable Dense Prediction

121	ExtDM: Distribution Extrapolation Diffusion Model for Video Prediction

122	ExtraNeRF: Visibility-Aware View Extrapolation of Neural Radiance Fields with Diffusion Models

123	Face2Diffusion for Fast and Editable Face Personalization

124	FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head Models

125	FakeInversion: Learning to Detect Images from Unseen Text-to-Image Models by Inverting Stable Diffusion

126	Fast ODE-based Sampling for Diffusion Models in Around 5 Steps

127	Few-shot Learner Parameterization by Diffusion Time-steps

128	FinePOSE: Fine-Grained Prompt-Driven 3D Human Pose Estimation via Diffusion Models

129	Fixed Point Diffusion Models

130	FlashEval: Towards Fast and Accurate Evaluation of Text-to-image Diffusion Generative Models

131	FlowDiffuser: Advancing Optical Flow Estimation with Diffusion Models

132	Fourier Priors-Guided Diffusion for Zero-Shot Joint Low-Light Enhancement and Deblurring

133	FreeControl: Training-Free Spatial Control of Any Text-to-Image Diffusion Model with Any Condition

134	FreeU: Free Lunch in Diffusion U-Net

135	Functional Diffusion

136	Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models

137	GaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models

138	GDA: Generalized Diffusion for Robust Test-time Adaptation

139	Generate Like Experts: Multi-Stage Font Generation by Incorporating Font Transfer Process into Diffusion Models

140	Generate Subgoal Images before Act: Unlocking the Chain-of-Thought Reasoning in Diffusion Model for Robot Manipulation with Multimodal Prompts

141	Generative Rendering: Controllable 4D-Guided Video Generation with 2D Diffusion Models

142	GenesisTex: Adapting Image Denoising Diffusion to Texture Space

143	GenTron: Diffusion Transformers for Image and Video Generation

144	Genuine Knowledge from Practice: Diffusion Test-Time Adaptation for Video Adverse Weather Removal

145	GPLD3D: Latent Diffusion of 3D Shape Generative Models by Enforcing Geometric and Physical Priors

146	Grid Diffusion Models for Text-to-Video Generation

147	HandDiff: 3D Hand Pose Estimation with Diffusion on Image-Point Cloud

148	HHMR: Holistic Hand Mesh Recovery by Enhancing the Multimodal Controllability of Graph Diffusion Models

149	Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation

150	Hierarchical Patch-wise Diffusion Models for High-Resolution Video Generation

151	HIR-Diff: Unsupervised Hyperspectral Image Restoration Via Improved Diffusion Models

152	HOIAnimator: Text-Prompt Human-Object Animations Generation with Perceptive Diffusion Models

153	HOIDiffusion: Generating Realistic 3D Hand-Object Interaction Data

154	HumanNorm: Learning Normal Diffusion Model for High-quality and Realistic 3D Human Generation

155	HumanRef: Single Image to 3D Human Generation via Reference-Guided Diffusion

156	ID-Blau: Image Deblurring by Implicit Diffusion-based reBLurring AUgmentation

157	Image Neural Field Diffusion Models

158	Image Restoration by Denoising Diffusion Models With Iteratively Preconditioned Guidance

159	ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object

160	Improving Training Efficiency of Diffusion Models via Multi-Stage Framework and Tailored Multi-Decoder Architectures

161	In-distribution Public Data Synthesis with Diffusion Models for Differentially Private Image Classification

162	InitNO: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization

163	InstanceDiffusion: Instance-level Control for Image Generation

164	Instruct 4D-to-4D: Editing 4D Scenes as Pseudo-3D Scenes Using 2D Diffusion

165	InstructDiffusion: A Generalist Modeling Interface for Vision Tasks

166	InstructVideo: Instructing Video Diffusion Models with Human Feedback

167	Intelligent Grimm - Open-ended Visual Storytelling via Latent Diffusion Models

168	InteractDiffusion: Interaction Control in Text-to-Image Diffusion Models

169	InterHandGen: Two-Hand Interaction Generation via Cascaded Reverse Diffusion

170	Intriguing Properties of Diffusion Models: An Empirical Study of the Natural Attack Capability in Text-to-Image Generative Models

171	Intrinsic Image Diffusion for Indoor Single-view Material Estimation

172	Inversion-Free Image Editing with Language-Guided Diffusion Models

173	IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images

174	It's All About Your Sketch: Democratising Sketch Control in Diffusion Models

175	JeDi: Joint-Image Diffusion Models for Finetuning-Free Personalized Text-to-Image Generation

176	LAKE-RED: Camouflaged Images Generation by Latent Background Knowledge Retrieval-Augmented Diffusion

177	Layout-Agnostic Scene Text Image Synthesis with Diffusion Models

178	Learned representation-guided diffusion models for large-image generation

179	Learning Diffusion Texture Priors for Image Restoration

180	Learning Spatial Adaptation and Temporal Coherence in Diffusion Models for Video Super-Resolution

181	LeftRefill: Filling Right Canvas based on Left Reference through Generalized Text-to-Image Diffusion Model

182	Light the Night: A Multi-Condition Diffusion Framework for Unpaired Low-Light Enhancement in Autonomous Driving

183	LightIt: Illumination Modeling and Control for Diffusion Models

184	Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation guided by the Characteristic Dance Primitives

185	MACE: Mass Concept Erasure in Diffusion Models

186	MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model

187	Make-Your-Anchor: A Diffusion-based 2D Avatar Generation Framework

188	MAS: Multi-view Ancestral Sampling for 3D motion generation using 2D diffusion

189	MatFuse: Controllable Material Generation with Diffusion Models

190	MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant

191	MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models

192	MetaCloak: Preventing Unauthorized Subject-driven Text-to-image Diffusion-based Synthesis via Meta-learning

193	MicroDiffusion: Implicit Representation-Guided Diffusion for 3D Reconstruction from Limited 2D Microscopy Projections

194	MimicDiffusion: Purifying Adversarial Perturbation via Mimicking Clean Diffusion Model

195	MMA-Diffusion: MultiModal Attack on Diffusion Models

196	Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation

197	Motion2VecSets: 4D Latent Vector Set Diffusion for Non-rigid Shape Reconstruction and Tracking

198	MotionEditor: Editing Video Motion via Content-Aware Diffusion

199	Move Anything with Layered Scene Diffusion

200	Multiway Point Cloud Mosaicking with Diffusion and Global Optimization

201	MVIP-NeRF: Multi-view 3D Inpainting on NeRF Scenes via Diffusion Prior

202	Neural Point Cloud Diffusion for Disentangled 3D Shape and Appearance Generation

203	Neural Sign Actors: A diffusion model for 3D sign language production from text

204	NoiseCLR: A Contrastive Learning Approach for Unsupervised Discovery of Interpretable Directions in Diffusion Models

205	NoiseCollage: A Layout-Aware Text-to-Image Diffusion Model Based on Noise Cropping and Merging

206	Object Pose Estimation via the Aggregation of Diffusion Features

207	Observation-Guided Diffusion Probabilistic Models

208	On the Scalability of Diffusion-based Text-to-Image Generation

209	One More Step: A Versatile Plug-and-Play Module for Rectifying Diffusion Schedule Flaws and Enhancing Low-Frequency Controls

210	One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion

211	One-dimensional Adapter to Rule Them All: Concepts, Diffusion Models and Erasing Applications

212	One-step Diffusion with Distribution Matching Distillation

213	Open-Vocabulary Attention Maps with Token Optimization for Semantic Segmentation in Diffusion Models

214	Optimizing Diffusion Noise Can Serve As Universal Motion Priors

215	Orthogonal Adaptation for Modular Customization of Diffusion Models

216	Overcoming Data Limitations for High-Quality Video Diffusion Models

217	Paint3D: Paint Anything 3D with Lighting-less Texture Diffusion Models

218	PAIR Diffusion: A Comprehensive Multimodal Object-Level Image Editor

219	PEEKABOO: Interactive Video Generation via Masked-Diffusion

220	Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging Perturbations That Efficiently Fool Customized Diffusion Models

221	PI3D: Efficient Text-to-3D Generation with Pseudo-Image Diffusion

222	Plug-and-Play Diffusion Distillation

223	Point Cloud Pre-training with Diffusion Models

224	PointInfinity: Resolution-Invariant Point Diffusion Models

225	PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models

226	Predicated Diffusion: Predicate Logic-Based Attention Guidance for Text-to-Image Diffusion Models

227	ProMark: Proactive Diffusion Watermarking for Causal Attribution

228	Prompt-Free Diffusion: Taking “Text” out of Text-to-Image Diffusion Models

229	Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models

230	R-Cyclic Diffuser: Reductive and Cyclic Latent Diffusion for 3D Clothed Human Digitalization

231	Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following

232	RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models

233	READ: Retrieval-Enhanced Asymmetric Diffusion for Motion Planning

234	Readout Guidance: Learning Control from Diffusion Features

235	RecDiffusion: Rectangling for Image Stitching with Diffusion Models

236	ReconFusion: 3D Reconstruction with Diffusion Priors

237	Relation Rectification in Diffusion Model

238	Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation

239	Residual Denoising Diffusion Models

240	Residual Learning in Diffusion Models

241	Rethinking Diffusion Model for Multi-Contrast MRI Super-Resolution

242	Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance

243	RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail Richness in Text-to-3D

244	RoHM: Robust Human Motion Reconstruction via Diffusion

245	Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion

246	SatSynth: Augmenting Image-Mask Pairs through Diffusion Models for Aerial Semantic Segmentation

247	Scaling Diffusion Models to Real-World 3D LiDAR Scene Completion

248	SCEdit: Efficient and Controllable Image Diffusion Generation via Skip Connection Editing

249	SceneTex: High-Quality Texture Synthesis for Indoor Scenes via Diffusion Priors

250	Score-Guided Diffusion for 3D Human Recovery

251	SD-DiT: Unleashing the Power of Self-supervised Discrimination in Diffusion Transformer

252	SD4Match: Learning to Prompt Stable Diffusion Model for Semantic Matching

253	SDDGR: Stable Diffusion-based Deep Generative Replay for Class Incremental Object Detection

254	Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners

255	Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model

256	Self-Adaptive Reality-Guided Diffusion for Artifact-Free Super-Resolution

257	Self-correcting LLM-controlled Diffusion

258	Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation

259	SemCity: Semantic Scene Generation with Triplane Diffusion

260	Shadow Generation for Composite Image Using Diffusion Model

261	SimAC: A Simple Anti-Customization Method against Text-to-Image Synthesis of Diffusion Models

262	SimDA: Simple Diffusion Adapter for Efficient Video Generation

263	Single Mesh Diffusion Models with Field Latents for Texture Generation

264	SingularTrajectory: Universal Trajectory Predictor Using Diffusion Model

265	SinSR: Diffusion-Based Image Super-Resolution in a Single Step

266	SiTH: Single-view Textured Human Reconstruction with Image-Conditioned Diffusion

267	SkillDiffuser: Interpretable Hierarchical Planning via Skill Abstractions in Diffusion-Based Task Execution

268	Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models

269	SNED: Superposition Network Architecture Search for Efficient Video Diffusion Model

270	SODA: Bottleneck Diffusion Models for Representation Learning

271	Solving Masked Jigsaw Puzzles with Diffusion Transformers

272	Space-time Diffusion Features for Zero-shot Text-driven Motion Transfer

273	StableVITON: Learning Semantic Correspondence with Latent Diffusion Model for Virtual Try-On

274	Structure Matters: Tackling the Semantic Discrepancy in Diffusion Models for Image Inpainting

275	Structure-Guided Adversarial Training of Diffusion Models

276	Style Injection in Diffusion: A Training-free Approach for Adapting Large-scale Diffusion Models for Style Transfer

277	SVDTree: Semantic Voxel Diffusion for Single Image Tree Reconstruction

278	SVGDreamer: Text Guided SVG Generation with Diffusion Model

279	SwiftBrush: One-Step Text-to-Image Diffusion Model with Variational Score Distillation

280	Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models

281	Taming Stable Diffusion for Text to 360$^{\circ}$ Panorama Image Generation

282	TexOct: Generating Textures of 3D Models with Octree-based Diffusion

283	Text-image Alignment for Diffusion-based Perception

284	Text-to-3D Generation with Bidirectional Diffusion using both 3D and 2D priors

285	Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers

286	Texture-Preserving Diffusion Models for High-Fidelity Virtual Try-On

287	TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion

288	TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models

289	TI2V-Zero: Zero-Shot Image Conditioning for Text-to-Video Diffusion Models

290	TIGER: Time-Varying Denoising Model for 3D Point Cloud Generation with Diffusion Process

291	TiNO-Edit: Timestep and Noise Optimization for Robust Diffusion-Based Image Editing

292	TokenCompose: Text-to-Image Diffusion with Token-level Supervision

293	Towards Accurate Post-training Quantization for Diffusion Models

294	Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation

295	Towards Memorization-Free Diffusion Models

296	Towards More Accurate Diffusion Model Acceleration with A Timestep Aligner

297	Towards Realistic Scene Generation with LiDAR Diffusion Models

298	Towards Understanding Cross and Self-Attention in Stable Diffusion for Text-Guided Image Editing

299	Training Diffusion Models Towards Diverse Image Generation with Reinforcement Learning

300	Training-Free Open-Vocabulary Segmentation with Offline Diffusion-Augmented Prototype Generation

301	TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models

302	UDiFF: Generating Conditional Unsigned Distance Fields with Optimal Wavelet Diffusion

303	UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs

304	UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures

305	Unmixing Diffusion for Self-Supervised Hyperspectral Image Denoising

306	Unsupervised Keypoints from Pretrained Diffusion Models

307	Upscale-A-Video: Temporal-Consistent Diffusion Model for Real-World Video Super-Resolution

308	UV-IDM: Identity-Conditioned Latent Diffusion Model for Face UV-Texture Generation

309	VecFusion: Vector Font Generation with Diffusion

310	Vector Graphics Generation via Mutually Impulsed Dual-domain Diffusion

311	Versatile Navigation under Partial Observability via Value-Guided Diffusion Policy

312	Video Interpolation with Diffusion Models

313	VideoBooth: Diffusion-based Video Generation with Image Prompts

314	Visual Anagrams: Synthesizing Multi-View Optical Illusions with Diffusion Models

315	Visual Layout Composer: Image-Vector Dual Diffusion Model for Design Layout Generation

316	ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models

317	VMC: Video Motion Customization using Temporal Attention Adaption for Text-to-Video Diffusion Models

318	Watermark-embedded Adversarial Examples for Copyright Protection against Diffusion Models

319	Wavelet-based Fourier Information Interaction with Frequency Diffusion Adjustment for Underwater Image Restoration

320	When StyleGAN Meets Stable Diffusion: a ${\mathcal{W}_+}$ Adapter for Personalized Image Generation

321	Wonder3D: Single Image to 3D using Cross-Domain Diffusion

322	WOUAF: Weight Modulation for User Attribution and Fingerprinting in Text-to-Image Diffusion Models

323	X-Adapter: Adding Universal Compatibility of Plugins for Upgraded Diffusion Model

324	Your Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models

