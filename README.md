# CVPR2024-Diffusion-Model

1	$CrowdDiff$: Multi-hypothesis Crowd Density Estimation using Diffusion Models   https://arxiv.org/abs/2303.12790

2	$\text{LaRE}^2$: Latent Reconstruction Error Based Method for Diffusion-Generated Image Detection  https://arxiv.org/abs/2403.17465

3	$MonoDiff$: Monocular 3D Object Detection and Pose Estimation with Diffusion Models

4	360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model  https://arxiv.org/abs/2401.06578

5	3DiffTection: 3D Object Detection with Geometry-aware Diffusion Features  https://arxiv.org/abs/2311.04391

6	6D-Diff: A Keypoint Diffusion Framework for 6D Object Pose Estimation  https://arxiv.org/abs/2401.00029

7	A Conditional Denoising Diffusion Probabilistic Model for Point Cloud Upsampling  https://arxiv.org/abs/2312.02719

8	A Unified Diffusion Framework for Scene-aware Human Motion Estimation from Sparse Signals  https://arxiv.org/abs/2404.04890

9	AAMDM: Accelerated Auto-regressive Motion Diffusion Model  https://arxiv.org/abs/2401.06146

10	Accelerating Diffusion Sampling with Optimized Time Steps  https://arxiv.org/abs/2402.17376

11	ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models  https://arxiv.org/abs/2311.14097

12	Action Detection via an Image Diffusion Process  https://arxiv.org/abs/2404.01051

13	AEROBLADE: Training-Free Detection of Latent Diffusion Images Using Autoencoder Reconstruction Error  https://arxiv.org/abs/2401.17879

14	Alchemist: Parametric Control of Material Properties with Diffusion Models  https://arxiv.org/abs/2312.02970

15	Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models  https://arxiv.org/abs/2312.13763

16	Amodal Completion via Progressive Mixed Context Diffusion  https://arxiv.org/abs/2312.15540

17	Analyzing and Improving the Training Dynamics of Diffusion Models  https://arxiv.org/abs/2312.02696

18	Arbitrary Motion Style Transfer with Multi-condition Motion Latent Diffusion Model

19	Arbitrary-Scale Image Generation and Upsampling using Latent Diffusion Model and Implicit Neural Decoder  https://arxiv.org/abs/2403.10255

20	As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D Diffusion Priors  https://arxiv.org/abs/2311.16739

21	Atlantis: Enabling Underwater Depth Estimation with Stable Diffusion  https://arxiv.org/abs/2312.12471

22	Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models 

23	AVID: Any-Length Video Inpainting with Diffusion Model  https://arxiv.org/abs/2312.03816

24	Balancing Act: Distribution-Guided Debiasing in Diffusion Models  https://arxiv.org/abs/2402.18206

25	Bayesian Diffusion Models for 3D Shape Reconstruction  https://arxiv.org/abs/2403.06973

26	Beyond First-Order Tweedie: Solving Inverse Problems using Latent Diffusion  https://arxiv.org/abs/2312.00852

27	Beyond Textual Constraints: Learning Novel Diffusion Conditions with Fewer Examples

28	Bidirectional Autoregessive Diffusion Model for Dance Generation

29	BIVDiff: A Training-free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models  https://arxiv.org/abs/2312.02813

30	Boosting Diffusion Models with Moving Average Sampling in Frequency Domain  https://arxiv.org/abs/2403.17870

31	Building Bridges across Spatial and Temporal Resolutions: Reference-Based Super-Resolution via Change Priors and Conditional Diffusion Model  https://arxiv.org/abs/2403.17460

32	Cache Me if You Can: Accelerating Diffusion Models through Block Caching  https://arxiv.org/abs/2312.03209

33	Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion?  https://arxiv.org/abs/2312.00084

34	Carve3D: Improving Multiview Reconstruction Consistency for Diffusion Models with RL Finetuning

35	CAT-DM: Controllable Accelerated Virtual Try-on with Diffusion Model  https://arxiv.org/abs/2311.18405

36	CCEdit: Creative and Controllable Video Editing via Diffusion Models  https://arxiv.org/abs/2309.16496

37	CDFormer: When Degradation Prediction Embraces Diffusion Model for Blind Image Super-Resolution

38	CGI-DM: Digital Copyright Authentication for Diffusion Models via Contrasting Gradient Inversion  https://arxiv.org/abs/2403.11162

39	Clockwork Diffusion: Efficient Generation With Model-Step Distillation  https://arxiv.org/abs/2312.08128

40	Co-Speech Gesture Video Generation via Motion-Decoupled Diffusion Model  https://arxiv.org/abs/2404.01862

41	Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis  https://arxiv.org/abs/2402.18078

42	CoDi: Conditional Diffusion Distillation for Higher-Fidelity and Faster Image Generation  https://arxiv.org/abs/2310.01407

43	CommonCanvas: Open Diffusion Models Trained on Creative-Commons Images  https://arxiv.org/abs/2310.16825

44	CONFORM: Contrast is All You Need for High-Fidelity Text-to-Image Diffusion Models  https://arxiv.org/abs/2312.06059

45	Confronting Ambiguity in 6D Object Pose Estimation via Score-Based Diffusion on SE(3)  https://arxiv.org/abs/2305.15873

46	ConsistDreamer: 3D-Consistent 2D Diffusion for High-Fidelity Scene Editing

47	ConsistNet: Enforcing 3D Consistency for Multi-view Images Diffusion  https://arxiv.org/abs/2310.10343

48	Contrastive Denoising Score for Text-guided Latent Diffusion Image Editing  https://arxiv.org/abs/2311.18608

49	ConvoFusion: Multi-Modal Conversational Diffusion for Co-Speech Gesture Synthesis  https://arxiv.org/abs/2403.17936

50	Correcting Diffusion Generation through Resampling  https://arxiv.org/abs/2312.06038

51	$\mathrm{D^4M}$: Dataset Distillation via Disentangled Diffusion Model

52	De-Diffusion Makes Text a Strong Cross-Modal Interface  https://arxiv.org/abs/2311.00618

53	DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations  https://arxiv.org/abs/2403.06951

54	Deep Equilibrium Diffusion Restoration with Parallel Sampling  https://arxiv.org/abs/2311.11600

55	DeepCache: Accelerating Diffusion Models for Free  https://arxiv.org/abs/2312.00858

56	DetDiffusion: Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception  https://arxiv.org/abs/2403.13304

57	Diff-BGM: A Diffusion Model for Video Background Music Generation

58	Diff-Plugin: Revitalizing Details for Diffusion-based Low-level Tasks  https://arxiv.org/abs/2403.00644

59	DiffAM: Diffusion-based Adversarial Makeup Transfer for Facial Privacy Protection

60	DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly  https://arxiv.org/abs/2402.19302

61	DiffCast: A Unified Framework via Residual Diffusion for Precipitation Nowcasting  https://arxiv.org/abs/2312.06734

62	DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image Editing  https://arxiv.org/abs/2402.02583

63	DiffForensics: Leveraging Diffusion Prior to Image Forgery Detection and Localization

64	DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation  https://arxiv.org/abs/2306.00519

65	DiffLoc: Diffusion Model for Outdoor LiDAR Localization

66	DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with Iterative Diffusion-Based Refinement  https://arxiv.org/abs/2311.17456

67	DiffMorpher: Unleashing the Capability of Diffusion Models for Image Morphing  https://arxiv.org/abs/2312.07409

68	DiffMOT: A Real-time Diffusion-based Multiple Object Tracker with Non-linear Prediction  https://arxiv.org/abs/2403.02075

69	DiffPerformer: Iterative Learning of Consistent Latent Guidance for Diffusion-based Human Video Generation

70	DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View Synthesis  https://arxiv.org/abs/2312.13016

71	DiffSal: Joint Audio and Video Learning for Diffusion Saliency Prediction  https://arxiv.org/abs/2403.01226

72	DiffSCI: Zero-Shot Snapshot Compressive Imaging via Iterative Spectral Diffusion Model  https://arxiv.org/abs/2311.11417

73	DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation  https://arxiv.org/abs/2401.04747

74	DiffuScene: Denoising Diffusion Models for Generative Indoor Scene Synthesis  https://arxiv.org/abs/2303.14207

75	Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion  https://arxiv.org/abs/2308.12469

76	DiffuseMix: Label-Preserving Data Augmentation with Diffusion Models

77	Diffusion 3D Features (Diff3F): Decorating Untextured Shapes with Distilled Semantic Features  https://arxiv.org/abs/2311.17024

78	Diffusion Handles: Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D  https://arxiv.org/abs/2312.02190

79	Diffusion Model Alignment Using Direct Preference Optimization  https://arxiv.org/abs/2311.12908

80	Diffusion Models Without Attention

81	Diffusion Reflectance Map: Single-Image Stochastic Inverse Rendering of Illumination and Reflectance  https://arxiv.org/abs/2312.04529

82	Diffusion Time-step Curriculum for One Image to 3D Generation  https://arxiv.org/abs/2404.04562

83	Diffusion-based Blind Text Image Super-Resolution  https://arxiv.org/abs/2312.08886

84	Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation

85	Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation  https://arxiv.org/abs/2309.02685

86	Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous and Instruction-guided Driving  https://arxiv.org/abs/2402.06559

87	Diffusion-FOF: Single-view Clothed Human Reconstruction via Diffusion-based Fourier Occupancy Field

88	DiffusionAvatars: Deferred Diffusion for High-fidelity 3D Head Avatars  https://arxiv.org/abs/2311.18635

89	DiffusionGAN3D: Boosting Text-guided 3D Generation and Domain Adaptation by Combining 3D GANs and Diffusion Priors  https://arxiv.org/abs/2312.16837

90	DiffusionLight: Light Probes for Free by Painting a Chrome Ball  https://arxiv.org/abs/2312.09168

91	DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data  https://arxiv.org/abs/2403.15389

92	DiffusionPoser: Real-time Human Motion Reconstruction From Arbitrary Sparse Sensors Using Autoregressive Diffusion  https://arxiv.org/abs/2308.16682

93	DiffusionRegPose: Enhancing Multi-Person Pose Estimation using a Diffusion-Based End-to-End Regression Approach

94	DiG-IN: Diffusion Guidance for Investigating Networks - Uncovering Classifier Differences, Neuron Visualisations, and Visual Counterfactual Explanations

95	Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion  https://arxiv.org/abs/2311.15980

96	DiSR-NeRF: Diffusion-Guided View-Consistent Super-Resolution NeRF  https://arxiv.org/abs/2404.00874

97	Distilling ODE Solvers of Diffusion Models into Smaller Steps  https://arxiv.org/abs/2309.16421

98	Distraction is All You Need: Memory-Efficient Image Immunization against Diffusion-Based Image Editing

99	DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models  https://arxiv.org/abs/2402.19481

100	Don’t drop your samples! Coherence-aware training benefits Conditional diffusion

101 DPHMs: Diffusion Parametric Head Models for Depth-based Tracking  https://arxiv.org/abs/2312.01068

102 DPMesh: Exploiting Diffusion Prior for Occluded Human Mesh Recovery  https://arxiv.org/abs/2404.01424

103 Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic Propagation  https://arxiv.org/abs/2404.01050

104 DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing  https://arxiv.org/abs/2306.14435

105 Draw Step by Step Like Human: Reconstructing CAD Construction Sequences from Point Clouds via Multimodal Diffusion.

106 DREAM: Diffusion Rectification and Estimation-Adaptive Models  https://arxiv.org/abs/2312.00210

107 DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models  https://arxiv.org/abs/2304.00916

108 DreamSalon: A Staged Diffusion Framework for Preserving Identity-Context in Editable Face Generation  https://arxiv.org/abs/2403.19235

109 Dysen-VDM: Empowering Dynamics-aware Text-to-Video Diffusion with LLMs  https://arxiv.org/abs/2308.13812

110 EasyDrag: Efficient Point-based Manipulation on Diffusion Models

111 ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation  https://arxiv.org/abs/2403.18807

112 Efficient Dataset Distillation via Minimax Diffusion  https://arxiv.org/abs/2311.15529

113 EfficientDreamer: High-Fidelity and Robust 3D Creation via Orthogonal-view Diffusion Priors  https://arxiv.org/abs/2308.13223

114 Egocentric Full Body Motion Capture with FisheyeViT and Diffusion-Based Motion Refinement

115 ElasticDiffusion: Training-free Arbitrary Size Image Generation  https://arxiv.org/abs/2311.18822

116 EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion Models  https://arxiv.org/abs/2401.04608

117 Emotional Speech-Driven 3D Body Animation via Disentangled Latent Diffusion  https://arxiv.org/abs/2312.04466

118 Enhance Image Classification Via Inter-Class Image Mixup With Diffusion Model  https://arxiv.org/abs/2403.19600

119 EpiDiff: Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion  https://arxiv.org/abs/2312.06725

120 Exploiting Diffusion Prior for Generalizable Dense Prediction  https://arxiv.org/abs/2311.18832

121 ExtDM: Distribution Extrapolation Diffusion Model for Video Prediction

122 ExtraNeRF: Visibility-Aware View Extrapolation of Neural Radiance Fields with Diffusion Models

123 Face2Diffusion for Fast and Editable Face Personalization  https://arxiv.org/abs/2403.05094

124 FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head Models  https://arxiv.org/abs/2312.08459

125 FakeInversion: Learning to Detect Images from Unseen Text-to-Image Models by Inverting Stable Diffusion

126 Fast ODE-based Sampling for Diffusion Models in Around 5 Steps  https://arxiv.org/abs/2312.00094

127 Few-shot Learner Parameterization by Diffusion Time-steps  https://arxiv.org/abs/2403.02649

128 FinePOSE: Fine-Grained Prompt-Driven 3D Human Pose Estimation via Diffusion Models

129 Fixed Point Diffusion Models

130 FlashEval: Towards Fast and Accurate Evaluation of Text-to-image Diffusion Generative Models  https://arxiv.org/abs/2403.16379

131 FlowDiffuser: Advancing Optical Flow Estimation with Diffusion Models

132 Fourier Priors-Guided Diffusion for Zero-Shot Joint Low-Light Enhancement and Deblurring

133 FreeControl: Training-Free Spatial Control of Any Text-to-Image Diffusion Model with Any Condition  https://arxiv.org/abs/2312.07536

134 FreeU: Free Lunch in Diffusion U-Net  https://arxiv.org/abs/2309.11497

135 Functional Diffusion

136 Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models  https://arxiv.org/abs/2404.04956

137 GaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models  https://arxiv.org/abs/2310.08529

138 GDA: Generalized Diffusion for Robust Test-time Adaptation  https://arxiv.org/abs/2404.00095

139 Generate Like Experts: Multi-Stage Font Generation by Incorporating Font Transfer Process into Diffusion Models

140 Generate Subgoal Images before Act: Unlocking the Chain-of-Thought Reasoning in Diffusion Model for Robot Manipulation with Multimodal Prompts

141 Generative Rendering: Controllable 4D-Guided Video Generation with 2D Diffusion Models  https://arxiv.org/abs/2312.01409

142 GenesisTex: Adapting Image Denoising Diffusion to Texture Space  https://arxiv.org/abs/2403.17782

143 GenTron: Diffusion Transformers for Image and Video Generation

144 Genuine Knowledge from Practice: Diffusion Test-Time Adaptation for Video Adverse Weather Removal  https://arxiv.org/abs/2403.07684

145 GPLD3D: Latent Diffusion of 3D Shape Generative Models by Enforcing Geometric and Physical Priors

146 Grid Diffusion Models for Text-to-Video Generation  https://arxiv.org/abs/2404.00234

147 HandDiff: 3D Hand Pose Estimation with Diffusion on Image-Point Cloud  https://arxiv.org/abs/2404.03159

148 HHMR: Holistic Hand Mesh Recovery by Enhancing the Multimodal Controllability of Graph Diffusion Models

149 Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation  https://arxiv.org/abs/2403.03890

150 Hierarchical Patch-wise Diffusion Models for High-Resolution Video Generation

151 HIR-Diff: Unsupervised Hyperspectral Image Restoration Via Improved Diffusion Models  https://arxiv.org/abs/2402.15865

152 HOIAnimator: Text-Prompt Human-Object Animations Generation with Perceptive Diffusion Models

153 HOIDiffusion: Generating Realistic 3D Hand-Object Interaction Data  https://arxiv.org/abs/2403.12011

154 HumanNorm: Learning Normal Diffusion Model for High-quality and Realistic 3D Human Generation  https://arxiv.org/abs/2310.01406

155 HumanRef: Single Image to 3D Human Generation via Reference-Guided Diffusion  https://arxiv.org/abs/2311.16961

156 ID-Blau: Image Deblurring by Implicit Diffusion-based reBLurring Augmentation  https://arxiv.org/abs/2312.10998

157 Image Neural Field Diffusion Models

158 Image Restoration by Denoising Diffusion Models With Iteratively Preconditioned Guidance  https://arxiv.org/abs/2312.16519

159 ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object  https://arxiv.org/abs/2403.18775

160 Improving Training Efficiency of Diffusion Models via Multi-Stage Framework and Tailored Multi-Decoder Architectures  https://arxiv.org/abs/2312.09181

161 In-distribution Public Data Synthesis with Diffusion Models for Differentially Private Image Classification

162 InitNO: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization  https://arxiv.org/abs/2404.04650

163 InstanceDiffusion: Instance-level Control for Image Generation  https://arxiv.org/abs/2402.03290

164 Instruct 4D-to-4D: Editing 4D Scenes as Pseudo-3D Scenes Using 2D Diffusion

165 InstructDiffusion: A Generalist Modeling Interface for Vision Tasks  https://arxiv.org/abs/2309.03895

166 InstructVideo: Instructing Video Diffusion Models with Human Feedback  https://arxiv.org/abs/2312.12490

167 Intelligent Grimm - Open-ended Visual Storytelling via Latent Diffusion Models  https://arxiv.org/abs/2306.00973

168 InteractDiffusion: Interaction Control in Text-to-Image Diffusion Models  https://arxiv.org/abs/2312.05849

169 InterHandGen: Two-Hand Interaction Generation via Cascaded Reverse Diffusion  https://arxiv.org/abs/2403.17422

170 Intriguing Properties of Diffusion Models: An Empirical Study of the Natural Attack Capability in Text-to-Image Generative Models

171 Intrinsic Image Diffusion for Indoor Single-view Material Estimation  https://arxiv.org/abs/2312.12274

172 Inversion-Free Image Editing with Language-Guided Diffusion Models

173 IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images  https://arxiv.org/abs/2404.00269

174 It's All About Your Sketch: Democratising Sketch Control in Diffusion Models  https://arxiv.org/abs/2403.07234

175 JeDi: Joint-Image Diffusion Models for Finetuning-Free Personalized Text-to-Image Generation

176 LAKE-RED: Camouflaged Images Generation by Latent Background Knowledge Retrieval-Augmented Diffusion  https://arxiv.org/abs/2404.00292

177 Layout-Agnostic Scene Text Image Synthesis with Diffusion Models

178 Learned representation-guided diffusion models for large-image generation  https://arxiv.org/abs/2312.07330

179 Learning Diffusion Texture Priors for Image Restoration

180 Learning Spatial Adaptation and Temporal Coherence in Diffusion Models for Video Super-Resolution  https://arxiv.org/abs/2403.17000

181 LeftRefill: Filling Right Canvas based on Left Reference through Generalized Text-to-Image Diffusion Model  https://arxiv.org/abs/2305.11577

182 Light the Night: A Multi-Condition Diffusion Framework for Unpaired Low-Light Enhancement in Autonomous Driving  https://arxiv.org/abs/2404.04804

183 LightIt: Illumination Modeling and Control for Diffusion Models  https://arxiv.org/abs/2403.10615

184 Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation guided by the Characteristic Dance Primitives  https://arxiv.org/abs/2403.10518

185 MACE: Mass Concept Erasure in Diffusion Models  https://arxiv.org/abs/2403.06135

186 MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model  https://arxiv.org/abs/2311.16498

187 Make-Your-Anchor: A Diffusion-based 2D Avatar Generation Framework  https://arxiv.org/abs/2403.16510

188 MAS: Multi-view Ancestral Sampling for 3D motion generation using 2D diffusion  https://arxiv.org/abs/2310.14729

189 MatFuse: Controllable Material Generation with Diffusion Models  https://arxiv.org/abs/2308.11408

190 MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant  https://arxiv.org/abs/2403.04290

191 MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models

192 MetaCloak: Preventing Unauthorized Subject-driven Text-to-image Diffusion-based Synthesis via Meta-learning  https://arxiv.org/abs/2311.13127

193 MicroDiffusion: Implicit Representation-Guided Diffusion for 3D Reconstruction from Limited 2D Microscopy Projections  https://arxiv.org/abs/2403.10815

194 MimicDiffusion: Purifying Adversarial Perturbation via Mimicking Clean Diffusion Model  https://arxiv.org/abs/2312.04802

195 MMA-Diffusion: MultiModal Attack on Diffusion Models  https://arxiv.org/abs/2311.17516

196 Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation  https://arxiv.org/abs/2401.04728

197 Motion2VecSets: 4D Latent Vector Set Diffusion for Non-rigid Shape Reconstruction and Tracking  https://arxiv.org/abs/2401.06614

198 MotionEditor: Editing Video Motion via Content-Aware Diffusion  https://arxiv.org/abs/2311.18830

199 Move Anything with Layered Scene Diffusion  https://arxiv.org/abs/2404.07178

200	Multiway Point Cloud Mosaicking with Diffusion and Global Optimization

201 MVIP-NeRF: Multi-view 3D Inpainting on NeRF Scenes via Diffusion Prior

202 Neural Point Cloud Diffusion for Disentangled 3D Shape and Appearance Generation  https://arxiv.org/abs/2312.14124

203 Neural Sign Actors: A diffusion model for 3D sign language production from text

204 NoiseCLR: A Contrastive Learning Approach for Unsupervised Discovery of Interpretable Directions in Diffusion Models  https://arxiv.org/abs/2312.05390

205 NoiseCollage: A Layout-Aware Text-to-Image Diffusion Model Based on Noise Cropping and Merging  https://arxiv.org/abs/2403.03485

206 Object Pose Estimation via the Aggregation of Diffusion Features  https://arxiv.org/abs/2403.18791

207 Observation-Guided Diffusion Probabilistic Models

208 On the Scalability of Diffusion-based Text-to-Image Generation  https://arxiv.org/abs/2404.02883

209 One More Step: A Versatile Plug-and-Play Module for Rectifying Diffusion Schedule Flaws and Enhancing Low-Frequency Controls  https://arxiv.org/abs/2311.15744

210 One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion  https://arxiv.org/abs/2311.07885

211 One-dimensional Adapter to Rule Them All: Concepts, Diffusion Models and Erasing Applications  https://arxiv.org/abs/2312.16145

212 One-step Diffusion with Distribution Matching Distillation  https://arxiv.org/abs/2311.18828

213 Open-Vocabulary Attention Maps with Token Optimization for Semantic Segmentation in Diffusion Models  https://arxiv.org/abs/2403.14291

214 Optimizing Diffusion Noise Can Serve As Universal Motion Priors  https://arxiv.org/abs/2312.11994

215 Orthogonal Adaptation for Modular Customization of Diffusion Models

216 Overcoming Data Limitations for High-Quality Video Diffusion Models  https://arxiv.org/abs/2401.09047

217 Paint3D: Paint Anything 3D with Lighting-less Texture Diffusion Models  https://arxiv.org/abs/2312.13913

218 PAIR Diffusion: A Comprehensive Multimodal Object-Level Image Editor  https://arxiv.org/abs/2303.17546

219 PEEKABOO: Interactive Video Generation via Masked-Diffusion  https://arxiv.org/abs/2312.07509

220 Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging Perturbations That Efficiently Fool Customized Diffusion Models

221 PI3D: Efficient Text-to-3D Generation with Pseudo-Image Diffusion  https://arxiv.org/abs/2312.09069

222 Plug-and-Play Diffusion Distillation

223 Point Cloud Pre-training with Diffusion Models  https://arxiv.org/abs/2311.14960

224 PointInfinity: Resolution-Invariant Point Diffusion Models  https://arxiv.org/abs/2404.03566

225 PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models  https://arxiv.org/abs/2402.08714

226 Predicated Diffusion: Predicate Logic-Based Attention Guidance for Text-to-Image Diffusion Models  https://arxiv.org/abs/2311.16117

227 ProMark: Proactive Diffusion Watermarking for Causal Attribution  https://arxiv.org/abs/2403.09914

228 Prompt-Free Diffusion: Taking “Text” out of Text-to-Image Diffusion Models  https://arxiv.org/abs/2305.16223

229 Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models  https://arxiv.org/abs/2312.12416

230 R-Cyclic Diffuser: Reductive and Cyclic Latent Diffusion for 3D Clothed Human Digitalization

231 Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following  https://arxiv.org/abs/2311.17002

232 RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models  https://arxiv.org/abs/2312.04524

233 READ: Retrieval-Enhanced Asymmetric Diffusion for Motion Planning

234 Readout Guidance: Learning Control from Diffusion Features  https://arxiv.org/abs/2312.02150

235 RecDiffusion: Rectangling for Image Stitching with Diffusion Models  https://arxiv.org/abs/2403.19164

236 ReconFusion: 3D Reconstruction with Diffusion Priors  https://arxiv.org/abs/2312.02981

237 Relation Rectification in Diffusion Model  https://arxiv.org/abs/2403.20249

238 Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation  https://arxiv.org/abs/2312.02145

239 Residual Denoising Diffusion Models

240 Residual Learning in Diffusion Models

241 Rethinking Diffusion Model for Multi-Contrast MRI Super-Resolution  https://arxiv.org/abs/2404.04785

242 Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance  https://arxiv.org/abs/2404.05384

243 RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail Richness in Text-to-3D  https://arxiv.org/abs/2311.16918

244 RoHM: Robust Human Motion Reconstruction via Diffusion  https://arxiv.org/abs/2401.08570

245 Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion  https://arxiv.org/abs/2401.10786

246 SatSynth: Augmenting Image-Mask Pairs through Diffusion Models for Aerial Semantic Segmentation  https://arxiv.org/abs/2403.16605

247 Scaling Diffusion Models to Real-World 3D LiDAR Scene Completion  https://arxiv.org/abs/2403.13470

248 SCEdit: Efficient and Controllable Image Diffusion Generation via Skip Connection Editing  https://arxiv.org/abs/2312.11392

249 SceneTex: High-Quality Texture Synthesis for Indoor Scenes via Diffusion Priors  https://arxiv.org/abs/2311.17261

250 Score-Guided Diffusion for 3D Human Recovery  https://arxiv.org/abs/2403.09623

251 SD-DiT: Unleashing the Power of Self-supervised Discrimination in Diffusion Transformer  https://arxiv.org/abs/2403.17004

252 SD4Match: Learning to Prompt Stable Diffusion Model for Semantic Matching  https://arxiv.org/abs/2310.17569

253 SDDGR: Stable Diffusion-based Deep Generative Replay for Class Incremental Object Detection  https://arxiv.org/abs/2402.17323

254 Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners  https://arxiv.org/abs/2402.17723

255 Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model  https://arxiv.org/abs/2403.11157

256 Self-Adaptive Reality-Guided Diffusion for Artifact-Free Super-Resolution  https://arxiv.org/abs/2403.16643

257 Self-correcting LLM-controlled Diffusion  https://arxiv.org/abs/2311.16090

258 Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation  https://arxiv.org/abs/2311.17216

259 SemCity: Semantic Scene Generation with Triplane Diffusion  https://arxiv.org/abs/2403.07773

260 Shadow Generation for Composite Image Using Diffusion Model  https://arxiv.org/abs/2403.15234

261 SimAC: A Simple Anti-Customization Method against Text-to-Image Synthesis of Diffusion Models  https://arxiv.org/abs/2312.07865

262 SimDA: Simple Diffusion Adapter for Efficient Video Generation  https://arxiv.org/abs/2308.09710

263 Single Mesh Diffusion Models with Field Latents for Texture Generation  https://arxiv.org/abs/2312.09250

264 SingularTrajectory: Universal Trajectory Predictor Using Diffusion Model  https://arxiv.org/abs/2403.18452

265 SinSR: Diffusion-Based Image Super-Resolution in a Single Step  https://arxiv.org/abs/2311.14760

266 SiTH: Single-view Textured Human Reconstruction with Image-Conditioned Diffusion  https://arxiv.org/abs/2311.15855

267 SkillDiffuser: Interpretable Hierarchical Planning via Skill Abstractions in Diffusion-Based Task Execution  https://arxiv.org/abs/2312.11598

268 Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models  https://arxiv.org/abs/2312.04410

269 SNED: Superposition Network Architecture Search for Efficient Video Diffusion Model

270 SODA: Bottleneck Diffusion Models for Representation Learning  https://arxiv.org/abs/2311.17901

271 Solving Masked Jigsaw Puzzles with Diffusion Transformers  https://arxiv.org/abs/2404.07292

272 Space-time Diffusion Features for Zero-shot Text-driven Motion Transfer  https://arxiv.org/abs/2311.17009

273 StableVITON: Learning Semantic Correspondence with Latent Diffusion Model for Virtual Try-On  https://arxiv.org/abs/2312.01725

274 Structure Matters: Tackling the Semantic Discrepancy in Diffusion Models for Image Inpainting  https://arxiv.org/abs/2403.19898

275 Structure-Guided Adversarial Training of Diffusion Models  https://arxiv.org/abs/2402.17563

276 Style Injection in Diffusion: A Training-free Approach for Adapting Large-scale Diffusion Models for Style Transfer  https://arxiv.org/abs/2312.09008

277 SVDTree: Semantic Voxel Diffusion for Single Image Tree Reconstruction

278 SVGDreamer: Text Guided SVG Generation with Diffusion Model  https://arxiv.org/abs/2312.16476

279 SwiftBrush: One-Step Text-to-Image Diffusion Model with Variational Score Distillation  https://arxiv.org/abs/2312.05239

280 Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models  https://arxiv.org/abs/2403.08381

281 Taming Stable Diffusion for Text to ${360}^{\circ}$ Panorama Image Generation  https://arxiv.org/abs/2404.07949

282 TexOct: Generating Textures of 3D Models with Octree-based Diffusion

283 Text-image Alignment for Diffusion-based Perception  https://arxiv.org/abs/2310.00031

284 Text-to-3D Generation with Bidirectional Diffusion using both 3D and 2D priors  https://arxiv.org/abs/2312.04963

285 Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers  https://arxiv.org/abs/2403.07214

286 Texture-Preserving Diffusion Models for High-Fidelity Virtual Try-On  https://arxiv.org/abs/2404.01089

287 TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion  https://arxiv.org/abs/2401.09416

288 TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models  https://arxiv.org/abs/2311.16503

289 TI2V-Zero: Zero-Shot Image Conditioning for Text-to-Video Diffusion Models

290 TIGER: Time-Varying Denoising Model for 3D Point Cloud Generation with Diffusion Process

291 TiNO-Edit: Timestep and Noise Optimization for Robust Diffusion-Based Image Editing

292 TokenCompose: Text-to-Image Diffusion with Token-level Supervision  https://arxiv.org/abs/2312.03626

293 Towards Accurate Post-training Quantization for Diffusion Models  https://arxiv.org/abs/2305.18723

294 Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation  https://arxiv.org/abs/2403.05239

295 Towards Memorization-Free Diffusion Models  https://arxiv.org/abs/2404.00922

296 Towards More Accurate Diffusion Model Acceleration with A Timestep Aligner  https://arxiv.org/abs/2310.09469

297 Towards Realistic Scene Generation with LiDAR Diffusion Models  https://arxiv.org/abs/2404.00815

298 Towards Understanding Cross and Self-Attention in Stable Diffusion for Text-Guided Image Editing  https://arxiv.org/abs/2403.03431

299 Training Diffusion Models Towards Diverse Image Generation with Reinforcement Learning

300	Training-Free Open-Vocabulary Segmentation with Offline Diffusion-Augmented Prototype Generation  https://arxiv.org/abs/2404.06542

301	TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models  https://arxiv.org/abs/2403.17005

302	UDiFF: Generating Conditional Unsigned Distance Fields with Optimal Wavelet Diffusion  https://arxiv.org/abs/2404.06851

303	UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs  https://arxiv.org/abs/2311.09257

304	UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures  https://arxiv.org/abs/2401.11078

305	Unmixing Diffusion for Self-Supervised Hyperspectral Image Denoising

306	Unsupervised Keypoints from Pretrained Diffusion Models  https://arxiv.org/abs/2312.00065

307	Upscale-A-Video: Temporal-Consistent Diffusion Model for Real-World Video Super-Resolution  https://arxiv.org/abs/2312.06640

308	UV-IDM: Identity-Conditioned Latent Diffusion Model for Face UV-Texture Generation

309	VecFusion: Vector Font Generation with Diffusion  https://arxiv.org/abs/2312.10540

310	Vector Graphics Generation via Mutually Impulsed Dual-domain Diffusion

311	Versatile Navigation under Partial Observability via Value-Guided Diffusion Policy  https://arxiv.org/abs/2404.02176

312	Video Interpolation with Diffusion Models  https://arxiv.org/abs/2404.01203

313	VideoBooth: Diffusion-based Video Generation with Image Prompts  https://arxiv.org/abs/2312.00777

314	Visual Anagrams: Synthesizing Multi-View Optical Illusions with Diffusion Models  https://arxiv.org/abs/2311.17919

315	Visual Layout Composer: Image-Vector Dual Diffusion Model for Design Layout Generation

316	ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models  https://arxiv.org/abs/2312.01305

317	VMC: Video Motion Customization using Temporal Attention Adaption for Text-to-Video Diffusion Models  https://arxiv.org/abs/2312.00845

318	Watermark-embedded Adversarial Examples for Copyright Protection against Diffusion Models

319	Wavelet-based Fourier Information Interaction with Frequency Diffusion Adjustment for Underwater Image Restoration  https://arxiv.org/abs/2311.16845

320	When StyleGAN Meets Stable Diffusion: a ${\mathcal{W}_+}$ Adapter for Personalized Image Generation  https://arxiv.org/abs/2311.17461

321	Wonder3D: Single Image to 3D using Cross-Domain Diffusion  https://arxiv.org/abs/2310.15008

322	WOUAF: Weight Modulation for User Attribution and Fingerprinting in Text-to-Image Diffusion Models  https://arxiv.org/abs/2306.04744

323	X-Adapter: Adding Universal Compatibility of Plugins for Upgraded Diffusion Model  https://arxiv.org/abs/2312.02238

324	Your Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models  https://arxiv.org/abs/2312.10835

